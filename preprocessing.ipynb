{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_extracted_data.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Fwd','Sign-off Name','Name','Raw Content','Non English','Email','Content'],inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Male Mapping\n",
    "# Step 1: Extract unique names that match the condition\n",
    "unique_names = df[df['Gender'] == 'M']['Standardised Name'].unique()\n",
    "\n",
    "# Step 2: Create a mapping dictionary\n",
    "male_name_mapping = {name: f'm{i+1}' for i, name in enumerate(unique_names)}\n",
    "\n",
    "# Step 3: Apply the mapping\n",
    "df['Mapped Name'] = df['Standardised Name'].map(male_name_mapping)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Female Mapping\n",
    "# Step 1: Extract unique names that match the condition\n",
    "unique_female_names = df[df['Gender'] == 'F']['Standardised Name'].unique()\n",
    "\n",
    "# Step 2: Create a mapping dictionary\n",
    "female_name_mapping = {name: f'f{i+1}' for i, name in enumerate(unique_female_names)}\n",
    "\n",
    "# Step 3: Apply the mapping\n",
    "# Create a temporary series for female names mapping\n",
    "temp_female_mapped = df['Standardised Name'].map(female_name_mapping)\n",
    "\n",
    "# Use combine_first to fill NaN values in the 'Mapped Name' with the female mapping\n",
    "df['Mapped Name'] = df['Mapped Name'].combine_first(temp_female_mapped)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the dictionary to a file\n",
    "with open('male_name_mapping.pkl', 'wb') as file:\n",
    "    pickle.dump(male_name_mapping, file)\n",
    "\n",
    "# Save the dictionary to a file\n",
    "with open('female_name_mapping.pkl', 'wb') as file:\n",
    "    pickle.dump(female_name_mapping, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Gender'] == 'F']['Standardised Name'].unique()\n",
    "df[df['Gender'] == 'F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['First Name','Standardised Name'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_drop = df[df['Cleaned Content'].isna()]\n",
    "display(rows_to_drop)\n",
    "df.drop(index=rows_to_drop.index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_drop = df[df['Gender'] == 'unknown']\n",
    "df.drop(index=rows_to_drop.index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_authors = df[df['Gender'] == 'M']['Mapped Name'].value_counts()\n",
    "print('Number of Unique male authors:', len(male_authors))\n",
    "\n",
    "\n",
    "male_authors_df = pd.DataFrame(male_authors)\n",
    "male_authors_df.reset_index(inplace=True)\n",
    "male_authors_df.columns = ['Mapped Name','Email Count']\n",
    "male_authors_df\n",
    "\n",
    "female_authors = df[df['Gender'] == 'F']['Mapped Name'].value_counts()\n",
    "print('Number of Unique female authors:', len(female_authors))\n",
    "\n",
    "female_authors_df = pd.DataFrame(female_authors)\n",
    "female_authors_df.reset_index(inplace=True)\n",
    "female_authors_df.columns = ['Mapped Name','Email Count']\n",
    "female_authors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_authors.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_authors.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_authors = df['Mapped Name'].value_counts()\n",
    "mixed_author = pd.DataFrame(mixed_authors)\n",
    "\n",
    "mixed_author.reset_index(inplace=True)\n",
    "mixed_author.columns = ['Mapped Name', 'Email Count']\n",
    "\n",
    "# Step 3: Drop duplicates in the original DataFrame to retain unique authors with their genders\n",
    "unique_authors = df[['Mapped Name', 'Gender']].drop_duplicates()\n",
    "\n",
    "# Step 4: Merge the new DataFrame with the unique authors DataFrame to retain the gender information\n",
    "mixed_authors_df = pd.merge(mixed_author, unique_authors, on='Mapped Name', how='left')\n",
    "\n",
    "# Display the new DataFrame\n",
    "mixed_authors_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA of the distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Calculate mean and median\n",
    "mean_male = male_authors.mean()\n",
    "median_male = male_authors.median()\n",
    "mean_female = female_authors.mean()\n",
    "median_female = female_authors.median()\n",
    "\n",
    "# Bar plot with annotations\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='Gender', y='Email Count', data=mixed_authors_df, estimator=np.mean, ci=None)\n",
    "plt.title('Mean Number of Emails per Author by Gender')\n",
    "plt.ylabel('Mean Number of Emails')\n",
    "plt.text(0, mean_male + 2, f'Median: {median_male:.1f}', ha='center', va='bottom', color='blue')\n",
    "plt.text(1, mean_female + 2, f'Median: {median_female:.1f}', ha='center', va='bottom', color='blue')\n",
    "plt.show()\n",
    "\n",
    "# Box plot with mean marker\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='Gender', y='Email Count', data=mixed_authors_df)\n",
    "sns.stripplot(x='Gender', y='Email Count', data=mixed_authors_df, color='orange', jitter=True, marker='o', alpha=0.5)\n",
    "plt.title('Distribution of Emails per Author by Gender')\n",
    "plt.ylabel('Number of Emails')\n",
    "plt.axhline(mean_male, color='blue', linestyle='--', label=f'Mean Male: {mean_male:.1f}')\n",
    "plt.axhline(mean_female, color='red', linestyle='--', label=f'Mean Female: {mean_female:.1f}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Table of summary statistics\n",
    "summary_stats = pd.DataFrame({\n",
    "    'Statistic': ['Mean', 'Median'],\n",
    "    'Male': [mean_male, median_male],\n",
    "    'Female': [mean_female, median_female]\n",
    "})\n",
    "print(summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter top 10 authors for each gender\n",
    "top10_male = male_authors_df.nlargest(10, 'Email Count')\n",
    "top10_female = female_authors_df.nlargest(10, 'Email Count')\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "# Plot for male authors\n",
    "sns.barplot(ax=axes[0], x='Mapped Name', y='Email Count', data=top10_male, palette='Blues_d')\n",
    "axes[0].set_title('Top 10 Male Authors by Email Count')\n",
    "axes[0].set_xlabel('Email Count')\n",
    "axes[0].set_ylabel('Author')\n",
    "\n",
    "# Plot for female authors\n",
    "sns.barplot(ax=axes[1], x='Mapped Name', y='Email Count', data=top10_female, palette='Reds_d')\n",
    "axes[1].set_title('Top 10 Female Authors by Email Count')\n",
    "axes[1].set_xlabel('Email Count')\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Separate data by gender\n",
    "male_df = male_authors_df\n",
    "female_df = female_authors_df\n",
    "\n",
    "# Calculate the threshold for the top 10%\n",
    "male_threshold = male_df['Email Count'].quantile(0.90)\n",
    "female_threshold = female_df['Email Count'].quantile(0.90)\n",
    "\n",
    "# Identify the top 10% authors\n",
    "top_10_male = male_df[male_df['Email Count'] >= male_threshold]\n",
    "top_10_female = female_df[female_df['Email Count'] >= female_threshold]\n",
    "\n",
    "# Sum the email contributions of the top 25% authors\n",
    "top_10_male_contribution = top_10_male['Email Count'].sum()\n",
    "top_10_female_contribution = top_10_female['Email Count'].sum()\n",
    "\n",
    "# Calculate the total email contributions for each gender\n",
    "total_male_emails = male_df['Email Count'].sum()\n",
    "total_female_emails = female_df['Email Count'].sum()\n",
    "\n",
    "# Calculate the percentage contribution of the top 25%\n",
    "top_10_male_percentage = (top_10_male_contribution / total_male_emails) * 100\n",
    "top_10_female_percentage = (top_10_female_contribution / total_female_emails) * 100\n",
    "\n",
    "# Display the results\n",
    "print(f\"Top 10% Male Authors Contribution: {top_10_male_contribution} emails ({top_10_male_percentage:.2f}% of total male emails)\")\n",
    "print(f\"Top 10% Female Authors Contribution: {top_10_female_contribution} emails ({top_10_female_percentage:.2f}% of total female emails)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Method\n",
    "Random sampling with a cap on each author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_male = df[df['Gender'] == 'M']\n",
    "print('Original number of posts by male:', len(df_male))\n",
    "\n",
    "# Assuming df_male is your dataframe with contributions from male authors and has columns 'author' and 'text'\n",
    "original_size = len(df_male)\n",
    "desired_sample_size = 26500  # Define your desired sample size from male authors\n",
    "initial_cap = 300  # Initial cap on contributions per author\n",
    "\n",
    "# Step 1: Shuffle the entire dataset of male authors to ensure randomness\n",
    "df_male_shuffled = df_male.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "# Step 2: Initialize an empty list to collect the final samples\n",
    "final_male_samples = []\n",
    "\n",
    "# Step 3: Create a dictionary to keep track of the number of contributions per male author in the sample\n",
    "male_author_counts = {}\n",
    "\n",
    "# Step 4: Iterate over the shuffled dataset and add to final_male_samples while respecting the cap\n",
    "for index, row in df_male_shuffled.iterrows():\n",
    "    author = row['Mapped Name']\n",
    "    if male_author_counts.get(author, 0) < initial_cap:\n",
    "        final_male_samples.append(row)\n",
    "        male_author_counts[author] = male_author_counts.get(author, 0) + 1\n",
    "    if len(final_male_samples) >= desired_sample_size:\n",
    "        break\n",
    "\n",
    "df_male_samples = pd.DataFrame(final_male_samples)\n",
    "\n",
    "# Step 5: Create the hold-out validation set from the remaining data\n",
    "df_male_remaining = df_male_shuffled.drop(df_male_samples.index)\n",
    "\n",
    "# Check the final sample sizes\n",
    "final_sample_size = len(df_male_samples)\n",
    "holdout_size = len(df_male_remaining)\n",
    "\n",
    "print(f\"Final sample size: {final_sample_size}\")\n",
    "print(f\"Hold-out validation set size: {holdout_size}\")\n",
    "df_male_samples['Mapped Name'].value_counts()[:30]\n",
    "\n",
    "print('\\nCap per male author:', initial_cap)\n",
    "print('Author maximum post cap:', initial_cap / desired_sample_size * 100)\n",
    "\n",
    "print('\\nBasic Statistics:')\n",
    "print(df_male_samples['Mapped Name'].value_counts().describe())\n",
    "print('\\nMedian:', df_male_samples['Mapped Name'].value_counts().median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_female = df[df['Gender'] == 'F']\n",
    "print('Original number of posts by female:', len(df_female))\n",
    "\n",
    "# Assuming df_male is your dataframe with contributions from male authors and has columns 'author' and 'text'\n",
    "original_size = len(df_female)\n",
    "desired_sample_size = 750  # Define your desired sample size from male authors\n",
    "initial_cap = 40  # Initial cap on contributions per author\n",
    "\n",
    "# Step 1: Shuffle the entire dataset of male authors to ensure randomness\n",
    "df_female_shuffled = df_female.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "# Step 2: Initialize an empty list to collect the final samples\n",
    "final_female_samples = []\n",
    "\n",
    "# Step 3: Create a dictionary to keep track of the number of contributions per male author in the sample\n",
    "female_author_counts = {}\n",
    "\n",
    "# Step 4: Iterate over the shuffled dataset and add to final_male_samples while respecting the cap\n",
    "for index, row in df_female_shuffled.iterrows():\n",
    "    author = row['Mapped Name']\n",
    "    if female_author_counts.get(author, 0) < initial_cap:\n",
    "        final_female_samples.append(row)\n",
    "        female_author_counts[author] = female_author_counts.get(author, 0) + 1\n",
    "    if len(final_female_samples) >= desired_sample_size:\n",
    "        break\n",
    "\n",
    "# Check the final sample size\n",
    "final_sample_size = len(final_female_samples)\n",
    "\n",
    "df_female_samples = pd.DataFrame(final_female_samples)\n",
    "\n",
    "# Step 5: Create the hold-out validation set from the remaining data\n",
    "df_female_remaining = df_female_shuffled.drop(df_female_samples.index)\n",
    "\n",
    "# Check the final sample sizes\n",
    "final_sample_size = len(df_female_samples)\n",
    "holdout_size = len(df_female_remaining)\n",
    "\n",
    "print(f\"Final sample size: {final_sample_size}\")\n",
    "print(f\"Hold-out validation set size: {holdout_size}\")\n",
    "\n",
    "print('\\nCap per female author:', initial_cap)\n",
    "print('Author maximum post cap:', initial_cap / desired_sample_size * 100)\n",
    "\n",
    "print('\\nBasic Statistics:')\n",
    "print(df_female_samples['Mapped Name'].value_counts().describe())\n",
    "print('\\nMedian:', df_female_samples['Mapped Name'].value_counts().median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples = pd.concat([df_male_samples, df_female_samples], axis=0)\n",
    "df_validation = pd.concat([df_male_remaining, df_female_remaining], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples.drop_duplicates(subset='Mapped Name')['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples_count = df_samples['Mapped Name'].value_counts()\n",
    "\n",
    "df_samples_count = pd.DataFrame(df_samples_count)\n",
    "df_samples_count.reset_index(inplace=True)\n",
    "df_samples_count.columns = ['Mapped Name','Email Count']\n",
    "\n",
    "# Step 3: Drop duplicates in the original DataFrame to retain unique authors with their genders\n",
    "unique_authors = df[['Mapped Name', 'Gender']].drop_duplicates()\n",
    "\n",
    "# Step 4: Merge the new DataFrame with the unique authors DataFrame to retain the gender information\n",
    "df_samples_count = pd.merge(df_samples_count, unique_authors, on='Mapped Name', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_mean_male = df_male_samples['Mapped Name'].value_counts().mean()\n",
    "sampled_mean_female = df_female_samples['Mapped Name'].value_counts().mean()\n",
    "\n",
    "\n",
    "# Box plot with mean marker\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Gender', y='Email Count', data=df_samples_count)\n",
    "sns.stripplot(x='Gender', y='Email Count', data=df_samples_count, color='orange', jitter=True, marker='o', alpha=0.5)\n",
    "plt.title('Distribution of Emails per Author by Gender')\n",
    "plt.ylabel('Number of Emails')\n",
    "plt.axhline(sampled_mean_male, color='blue', linestyle='--', label=f'Mean Male: {sampled_mean_male:.1f}')\n",
    "plt.axhline(sampled_mean_female, color='red', linestyle='--', label=f'Mean Female: {sampled_mean_female:.1f}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define features and their functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1: Word Count - F4: Vodabulary Richness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexcial Features F1-F4\n",
    "# Function to count words\n",
    "def word_count(text):\n",
    "    if pd.isnull(text):\n",
    "        return 0\n",
    "    # Define a regular expression pattern that matches words\n",
    "    # This pattern will match sequences of alphanumeric characters and apostrophes (e.g., \"don't\")\n",
    "    words = re.findall(r\"\\b\\w+(?:[-']\\w+)*\\b\", text)\n",
    "    return len(words)\n",
    "\n",
    "# Function to count characters\n",
    "def character_count(text):\n",
    "    if pd.isnull(text):\n",
    "        return 0\n",
    "    return len(text)\n",
    "\n",
    "# Function to calculate average word length\n",
    "def average_word_length(text):\n",
    "    if pd.isnull(text) or len(text.split()) == 0:\n",
    "        return 0\n",
    "    words = re.findall(r\"\\b\\w+(?:[-']\\w+)*\\b\", text)\n",
    "    # Check if words is not empty to avoid division by zero\n",
    "    if len(words) == 0:\n",
    "        return 0\n",
    "    return sum(len(word) for word in words) / len(words)\n",
    "\n",
    "# Yule's K\n",
    "def vocabulary_richness(text):\n",
    "    \n",
    "    # Tokenize the text into words using a regular expression\n",
    "    words = re.findall(r\"\\b\\w+(?:[-']\\w+)*\\b\", text.lower())\n",
    "    \n",
    "    # Total number of words\n",
    "    total_words = len(words)\n",
    "    if total_words == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Calculate the frequency of each word\n",
    "    word_freq = Counter(words)\n",
    "    \n",
    "    # Calculate Yule's K\n",
    "    sum_fi_i_minus_1 = sum(freq * (freq - 1) for freq in word_freq.values())\n",
    "    k_value = 10**4 * sum_fi_i_minus_1 / total_words**2\n",
    "    \n",
    "    return k_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the functions to the Content column\n",
    "df_samples['F1 Word Count'] = df_samples['Cleaned Content'].apply(word_count).astype(int)\n",
    "df_samples['F2 Character Count'] = df_samples['Cleaned Content'].apply(character_count)\n",
    "df_samples['F3 Average Word Length'] = df_samples['Cleaned Content'].apply(average_word_length)\n",
    "df_samples['F4 Vocabulary Richness'] = df_samples['Cleaned Content'].apply(vocabulary_richness)\n",
    "\n",
    "df_validation['F1 Word Count'] = df_validation['Cleaned Content'].apply(word_count).astype(int)\n",
    "df_validation['F2 Character Count'] = df_validation['Cleaned Content'].apply(character_count)\n",
    "df_validation['F3 Average Word Length'] = df_validation['Cleaned Content'].apply(average_word_length)\n",
    "df_validation['F4 Vocabulary Richness'] = df_validation['Cleaned Content'].apply(vocabulary_richness)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F5: Average Sentence Length - F8: Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import pos_tag\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# F5: Average Sentence Length\n",
    "def average_sentence_length(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 0\n",
    "    sentences = sent_tokenize(text)\n",
    "    if len(sentences) == 0:\n",
    "        return 0\n",
    "    total_words = sum(word_count(sentence) for sentence in sentences)\n",
    "    return total_words / len(sentences)\n",
    "\n",
    "# F6: Part-of-Speech (POS) Tags Distribution\n",
    "def pos_tags_distribution(text):\n",
    "    if not isinstance(text, str):\n",
    "        return {}\n",
    "    words = word_tokenize(text)\n",
    "    pos_tags = pos_tag(words)\n",
    "\n",
    "    exclude_tags = ['$',\"''\",'(',')',',','--','.',':','``','#']\n",
    "\n",
    "    # Count POS tags, excluding specified tags\n",
    "    pos_counts = Counter(tag for word, tag in pos_tags if tag not in exclude_tags)\n",
    "    total_tags = sum(pos_counts.values())\n",
    "    return {tag: count / total_tags for tag, count in pos_counts.items()}\n",
    "\n",
    "# F7: Sentence Complexity (Number of Clauses per Sentence)\n",
    "def sentence_complexity(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 0\n",
    "    sentences = sent_tokenize(text)\n",
    "    if len(sentences) == 0:\n",
    "        return 0\n",
    "    clause_indicator_words = ['that', 'which', 'who', 'whom', 'whose', 'because', 'since', 'unless', 'although', 'if', 'when', 'while', 'until', 'before', 'after', 'as', 'though', 'even though']\n",
    "    total_clauses = sum(sum(1 for word in word_tokenize(sentence) if word.lower() in clause_indicator_words) for sentence in sentences)\n",
    "    return total_clauses / len(sentences)\n",
    "\n",
    "# F8: Punctuation Usage Counts\n",
    "def punctuation_usage(text):\n",
    "    if not isinstance(text, str):\n",
    "        return {}\n",
    "    \n",
    "    # Define the punctuation marks to consider\n",
    "    punctuation_marks = ['.', ',', '!', '?', ';', ':', \"'\"]\n",
    "    \n",
    "    # Count the punctuation marks in the text\n",
    "    punctuation_counts = Counter(char for char in text if char in punctuation_marks)\n",
    "    \n",
    "    # Calculate the total number of punctuation marks\n",
    "    total_punctuation = sum(punctuation_counts.values())\n",
    "    \n",
    "    # Calculate the distribution by dividing the count of each mark by the total\n",
    "    punctuation_distribution = {mark: count / total_punctuation for mark, count in punctuation_counts.items()} if total_punctuation > 0 else {}\n",
    "    \n",
    "    return punctuation_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the functions to the Content column\n",
    "df_samples['F5 Sentence Length'] = df_samples['Cleaned Content'].apply(average_sentence_length)\n",
    "df_samples['F6 POS Tags Distribution'] = df_samples['Cleaned Content'].apply(pos_tags_distribution)\n",
    "df_samples['F42 Sentence Complexity'] = df_samples['Cleaned Content'].apply(sentence_complexity)\n",
    "df_samples['F43 Punctuation Usage'] = df_samples['Cleaned Content'].apply(punctuation_usage)\n",
    "\n",
    "df_validation['F5 Sentence Length'] = df_validation['Cleaned Content'].apply(average_sentence_length)\n",
    "df_validation['F6 POS Tags Distribution'] = df_validation['Cleaned Content'].apply(pos_tags_distribution)\n",
    "df_validation['F42 Sentence Complexity'] = df_validation['Cleaned Content'].apply(sentence_complexity)\n",
    "df_validation['F43 Punctuation Usage'] = df_validation['Cleaned Content'].apply(punctuation_usage)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F50: Readability - F52 Politeness Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import textstat\n",
    "\n",
    "# F9: Define the function to calculate Flesch Reading Ease Score\n",
    "def flesch_reading_ease(text):\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "    return textstat.flesch_reading_ease(text)\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# F10: Define the function to calculate formality score\n",
    "def formality_score(text):\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "    \n",
    "    # Tokenize and POS tag the text\n",
    "    words = word_tokenize(text)\n",
    "    pos_tags = pos_tag(words)\n",
    "    \n",
    "    # Count POS tags\n",
    "    pos_counts = Counter(tag for word, tag in pos_tags)\n",
    "    \n",
    "    # Define counts for formal and informal categories\n",
    "    formal = pos_counts['NN'] + pos_counts['NNS'] + pos_counts['NNP'] + pos_counts['NNPS'] + pos_counts['JJ'] + pos_counts['JJR'] + pos_counts['JJS'] + pos_counts['IN'] + pos_counts['DT']\n",
    "    informal = pos_counts['PRP'] + pos_counts['PRP$'] + pos_counts['VB'] + pos_counts['VBD'] + pos_counts['VBG'] + pos_counts['VBN'] + pos_counts['VBP'] + pos_counts['VBZ'] + pos_counts['RB'] + pos_counts['RBR'] + pos_counts['RBS'] + pos_counts['UH']\n",
    "    \n",
    "    # Calculate formality score\n",
    "    f_score = ((formal - informal) + 100) / 2\n",
    "    return f_score\n",
    "\n",
    "# Define polite words and phrases\n",
    "polite_words = set([\n",
    "    'please', 'thank you', 'ta', 'thanks', 'sorry', 'excuse me', 'would you mind', 'could you',\n",
    "    'would you be so kind', 'I would appreciate', 'if it\\'s not too much trouble',\n",
    "    'thanks', 'cheers', 'much appreciated', 'kindly', 'pardon', 'beg your pardon',\n",
    "    'if you don\\'t mind', 'grateful', 'obliged', 'do me a favor', 'be so kind',\n",
    "    'please do', 'be kind enough', 'thankful', 'respectfully', 'with respect',\n",
    "    'if I may', 'if I might', 'if it pleases you', 'would it trouble you'\n",
    "])\n",
    "\n",
    "# Define impolite words and phrases\n",
    "impolite_words = set([\n",
    "    'stupid', 'idiot', 'dumb', 'shut up', 'shut your mouth', 'suck', 'jerk',\n",
    "    'moron', 'fool', 'loser', 'annoying', 'pathetic', 'horrible', 'dick', 'bitch',\n",
    "    'asshole', 'screw you', 'piss off', 'damn', 'crap', 'bastard', 'hell', 'shit',\n",
    "    'fuck', 'fucking', 'freak', 'douche', 'scum', 'trash', 'worthless'\n",
    "])\n",
    "\n",
    "# F10: Define the function to calculate politeness degree\n",
    "def politeness_degree(text):\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "    \n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text.lower())\n",
    "    \n",
    "    # Count polite and impolite words\n",
    "    polite_count = sum(1 for word in words if word in polite_words)\n",
    "    impolite_count = sum(1 for word in words if word in impolite_words)\n",
    "    \n",
    "    # Calculate total words\n",
    "    total_words = len(words)\n",
    "    if total_words == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Calculate politeness score\n",
    "    politeness_score = (polite_count - impolite_count) / total_words\n",
    "    return politeness_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the Content column\n",
    "df_samples['F50 Readability Score'] = df_samples['Cleaned Content'].apply(flesch_reading_ease)\n",
    "df_samples['F51 Formality Score'] = df_samples['Cleaned Content'].apply(formality_score)\n",
    "df_samples['F52 Politeness Degree'] = df_samples['Cleaned Content'].apply(politeness_degree)\n",
    "\n",
    "df_validation['F50 Readability Score'] = df_validation['Cleaned Content'].apply(flesch_reading_ease)\n",
    "df_validation['F51 Formality Score'] = df_validation['Cleaned Content'].apply(formality_score)\n",
    "df_validation['F52 Politeness Degree'] = df_validation['Cleaned Content'].apply(politeness_degree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import contractions\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Define common abbreviations\n",
    "abbreviations = {\n",
    "    \"u\": \"you\",\n",
    "    \"r\": \"are\",\n",
    "    \"ur\": \"your\",\n",
    "    \"lol\": \"laughing out loud\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"idk\": \"I don't know\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"gtg\": \"got to go\",\n",
    "    \"ttyl\": \"talk to you later\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"thx\": \"thanks\",\n",
    "    \"plz\": \"please\",\n",
    "    \"w/\": \"with\",\n",
    "    \"w/o\": \"without\",\n",
    "}\n",
    "\n",
    "# Function to expand contractions\n",
    "def expand_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "# Function to convert abbreviations\n",
    "def convert_abbreviations(text):\n",
    "    words = text.split()\n",
    "    converted_words = [abbreviations.get(word.lower(), word) for word in words]\n",
    "    return ' '.join(converted_words)\n",
    "\n",
    "# Main function to clean and normalize text\n",
    "def clean_normalize_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "    text = expand_contractions(text)\n",
    "    text = convert_abbreviations(text)\n",
    "    # text = correct_spelling(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define stop words and punctuation\n",
    "stop_words = set(stopwords.words('english'))\n",
    "negation_words = {'not', 'no', 'never', 'none', 'nobody', 'nothing', 'neither', 'nowhere', 'hardly', 'scarcely', 'barely'}\n",
    "stop_words = stop_words - negation_words\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "# Function to remove stop words, punctuation, and special characters\n",
    "def remove_stopwords_punctuation(text):\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words, punctuation, non-alphabetic tokens, and single alphabet characters\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words and word not in punctuation and word.isalpha() and len(word) > 1]\n",
    "    \n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "#  Initialize the WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "# Function to lemmatize tokens\n",
    "def lemmatize_tokens(tokens):\n",
    "    return [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in tokens]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the cleaning and normalization function to the Content column\n",
    "df_samples['Normalized Content'] = df_samples['Cleaned Content'].apply(clean_normalize_text)\n",
    "# Apply the tokenization and removal function to the Normalized Content column\n",
    "df_samples['Tokenized Content'] = df_samples['Normalized Content'].apply(remove_stopwords_punctuation)\n",
    "# Apply the lemmatization function to the Tokenized Content column\n",
    "df_samples['Lemmatized Content'] = df_samples['Tokenized Content'].apply(lemmatize_tokens)\n",
    "\n",
    "# Apply the cleaning and normalization function to the Content column\n",
    "df_validation['Normalized Content'] = df_validation['Cleaned Content'].apply(clean_normalize_text)\n",
    "# Apply the tokenization and removal function to the Normalized Content column\n",
    "df_validation['Tokenized Content'] = df_validation['Normalized Content'].apply(remove_stopwords_punctuation)\n",
    "# Apply the lemmatization function to the Tokenized Content column\n",
    "df_validation['Lemmatized Content'] = df_validation['Tokenized Content'].apply(lemmatize_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F12 Function to get sentiment polarity\n",
    "def get_sentiment_polarity(tokens):\n",
    "    if tokens is None:\n",
    "        return None\n",
    "    text = ' '.join(tokens)\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# F13 Function to get subjectivity\n",
    "def get_subjectivity(tokens):\n",
    "    if tokens is None:\n",
    "        return None\n",
    "    text = ' '.join(tokens)\n",
    "    return TextBlob(text).sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples['F53 Sentiment Polarity'] = df_samples['Lemmatized Content'].apply(get_sentiment_polarity)\n",
    "df_samples['F54 Subjectivity'] = df_samples['Lemmatized Content'].apply(get_subjectivity)\n",
    "\n",
    "df_validation['F53 Sentiment Polarity'] = df_validation['Lemmatized Content'].apply(get_sentiment_polarity)\n",
    "df_validation['F54 Subjectivity'] = df_validation['Lemmatized Content'].apply(get_subjectivity)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Step 1: Define or load stopwords\n",
    "nltk.download('stopwords')\n",
    "common_words = set(stopwords.words('english'))\n",
    "# Add custom stopwords if needed\n",
    "common_words.update(['not', 'get', 'would', 'like', 'even', 'one', 'go', 'make', 'see', 'say', 'know', 'u', \n",
    "                     'well', 'say', 'think', 'like', 'time', 'make', 'look', 'could', 'no', 'come', \n",
    "                     'last', 'even', 'still', 'much', 'really', 'want', 'need', 'right', \n",
    "                     'take', 'way', 'thing', 'best', 'play', 'give', 'u', 'seem', 'also', 'bit', 'let'])\n",
    "\n",
    "# Step 2: Filter stopwords from the Lemmatized Content\n",
    "def remove_stopwords(text):\n",
    "    return [word for word in text if word not in common_words]\n",
    "\n",
    "df_samples['Updated Lemmatized Content'] = df_samples['Lemmatized Content'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Remove common words \n",
    "\n",
    "# Create a dictionary and corpus for LDA\n",
    "unigram_dictionary = corpora.Dictionary(df_samples['Updated Lemmatized Content'])\n",
    "corpus = [unigram_dictionary.doc2bow(text) for text in df_samples['Updated Lemmatized Content']]\n",
    "\n",
    "# Function to get topic distribution for each document\n",
    "def get_topic_distribution(lda_model, corpus, num_topics):\n",
    "    topic_distributions = []\n",
    "    for doc in corpus:\n",
    "        topic_dist = [0] * num_topics\n",
    "        for topic_num, prob in lda_model.get_document_topics(doc):\n",
    "            topic_dist[topic_num] = prob\n",
    "        topic_distributions.append(topic_dist)\n",
    "    return topic_distributions\n",
    "\n",
    "# Build LDA model\n",
    "num_topics = 5\n",
    "lda_unigram_model = LdaModel(corpus, num_topics=num_topics, id2word=unigram_dictionary, passes=40, alpha='auto', eta='auto', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the most common topics\n",
    "topics = lda_unigram_model.print_topics(num_words=15)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract words and their weights for a specific topic (e.g., topic 0)\n",
    "topic_words = dict(lda_unigram_model.show_topic(4, topn=15))\n",
    "string =  str(topic_words.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all single quotation marks\n",
    "string_without_quotes = string.replace(\"'\", \"\")\n",
    "\n",
    "# Print the result\n",
    "print(string_without_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(num_topics):\n",
    "    plt.figure()\n",
    "    topic_words = dict(lda_unigram_model.show_topic(i, topn=20))\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(topic_words)\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f'Topic {i}')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F55: Topic Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get topic distribution for each document\n",
    "df_samples['F55 Topic Distribution'] = get_topic_distribution(lda_unigram_model, corpus, num_topics)\n",
    "\n",
    "val_corpus = [unigram_dictionary.doc2bow(text) for text in df_validation['Lemmatized Content']]\n",
    "df_validation['F55 Topic Distribution'] = get_topic_distribution(lda_unigram_model, val_corpus, num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples_copy = df_samples.copy()\n",
    "df_validation_copy = df_validation.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting\n",
    "df_samples = df_samples_copy.reset_index(drop=True)\n",
    "df_validation = df_validation_copy.reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples = df_samples.reset_index(drop=True)\n",
    "df_validation = df_validation.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_and_drop_feature_column(df, feature_column):\n",
    "\n",
    "    # Expand the dictionary into separate columns\n",
    "    expanded_df = df[feature_column].apply(pd.Series)\n",
    "    \n",
    "    # Arrange the POS tags (column names) in ascending order\n",
    "    expanded_df = expanded_df.reindex(sorted(expanded_df.columns), axis=1)\n",
    "    \n",
    "    # Join the expanded columns back to the original DataFrame\n",
    "    df = df.join(expanded_df)\n",
    "    \n",
    "    # Drop the original feature column\n",
    "    df = df.drop(columns=[feature_column])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F6 POS Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Assuming df_samples and df_validation have the expanded POS features\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Expand the dictionary into separate columns\n",
    "expanded_f6 = df_samples['F6 POS Tags Distribution'].apply(pd.Series)\n",
    "# Arrange the POS tags (column names) in ascending order\n",
    "expanded_f6 = expanded_f6.reindex(sorted(expanded_f6.columns), axis=1)\n",
    "\n",
    "POS_list = list(expanded_f6.columns)\n",
    "\n",
    "i = 6\n",
    "new_list = []\n",
    "for POS in POS_list:\n",
    "    new = 'F' + str(i) + ' ' + POS\n",
    "    new_list.append(new)\n",
    "    i += 1\n",
    "\n",
    "new_list\n",
    "rename_dict = dict(zip(POS_list,new_list))\n",
    "\n",
    "print(rename_dict)\n",
    "\n",
    "df_samples = expand_and_drop_feature_column(df_samples, 'F6 POS Tags Distribution')\n",
    "df_validation = expand_and_drop_feature_column(df_validation, 'F6 POS Tags Distribution')\n",
    "\n",
    "df_samples = df_samples.rename(columns=rename_dict)\n",
    "df_validation = df_validation.rename(columns=rename_dict)\n",
    "\n",
    "display(df_samples[new_list].head())\n",
    "\n",
    "\n",
    "# Fit and transform the df_samples dataset\n",
    "df_samples[new_list] = scaler.fit_transform(df_samples[new_list])\n",
    "\n",
    "# Transform the df_validation dataset (using the same scaler fit on the training set)\n",
    "df_validation[new_list] = scaler.transform(df_validation[new_list])\n",
    "\n",
    "display(df_samples[new_list].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F43 Punctuation Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand the dictionary into separate columns\n",
    "expanded_f43 = df_samples['F43 Punctuation Usage'].apply(pd.Series)\n",
    "# Arrange the POS tags (column names) in ascending order\n",
    "expanded_f43 = expanded_f43.reindex(sorted(expanded_f43.columns), axis=1)\n",
    "\n",
    "punc_list = list(expanded_f43.columns)\n",
    "\n",
    "i = 43\n",
    "new_list = []\n",
    "for punc in punc_list:\n",
    "    new = 'F' + str(i) + ' ' + punc\n",
    "    new_list.append(new)\n",
    "    i += 1\n",
    "\n",
    "rename_dict = dict(zip(punc_list,new_list))\n",
    "print(rename_dict)\n",
    "\n",
    "df_samples = expand_and_drop_feature_column(df_samples, 'F43 Punctuation Usage')\n",
    "df_validation = expand_and_drop_feature_column(df_validation, 'F43 Punctuation Usage')\n",
    "\n",
    "df_samples = df_samples.rename(columns=rename_dict)\n",
    "df_validation = df_validation.rename(columns=rename_dict)\n",
    "\n",
    "# Apply normalization to the df_samples dataset\n",
    "df_samples[new_list] = scaler.fit_transform(df_samples[new_list])\n",
    "\n",
    "# Apply normalization to the df_validation dataset\n",
    "df_validation[new_list] = scaler.transform(df_validation[new_list])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F55 Topic Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand the dictionary into separate columns\n",
    "expanded_f55 = df_samples['F55 Topic Distribution'].apply(pd.Series)\n",
    "# Arrange the POS tags (column names) in ascending order\n",
    "expanded_f55 = expanded_f55.reindex(sorted(expanded_f55.columns), axis=1)\n",
    "\n",
    "topic_list = list(expanded_f55.columns)\n",
    "\n",
    "i = 55\n",
    "j = 1\n",
    "new_list = []\n",
    "for topic in topic_list:\n",
    "    new = 'F' + str(i) + ' Topic ' + str(j)\n",
    "    new_list.append(new)\n",
    "    i += 1\n",
    "    j += 1\n",
    "\n",
    "rename_dict = dict(zip(topic_list,new_list))\n",
    "print(rename_dict)\n",
    "\n",
    "df_samples = expand_and_drop_feature_column(df_samples, 'F55 Topic Distribution')\n",
    "df_validation = expand_and_drop_feature_column(df_validation, 'F55 Topic Distribution')\n",
    "\n",
    "df_samples = df_samples.rename(columns=rename_dict)\n",
    "df_validation = df_validation.rename(columns=rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining F56 Topic 2 and F57 Topic 3\n",
    "df_samples['F56 Topic 2'] = df_samples['F56 Topic 2'] + df_samples['F57 Topic 3']\n",
    "df_samples = df_samples.drop(columns=['F57 Topic 3'])\n",
    "\n",
    "df_validation['F56 Topic 2'] = df_validation['F56 Topic 2'] + df_validation['F57 Topic 3']\n",
    "df_validation = df_validation.drop(columns=['F57 Topic 3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_list = ['F58 Topic 4', 'F59 Topic 5']\n",
    "new_list = ['F57 Topic 3', 'F58 Topic 4']\n",
    "rename_dict = dict(zip(topic_list,new_list))\n",
    "\n",
    "df_samples = df_samples.rename(columns=rename_dict)\n",
    "df_validation = df_validation.rename(columns=rename_dict)\n",
    "\n",
    "df_samples.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create New df that contains Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_exclude = ['Subject', 'Quote', 'Normalized Content', 'Tokenized Content', 'Lemmatized Content']\n",
    "\n",
    "features = ['ID', 'Gender', 'Mapped Name', 'Cleaned Content',\n",
    "       'F1 Word Count', 'F2 Character Count', 'F3 Average Word Length',\n",
    "       'F4 Vocabulary Richness', 'F5 Sentence Length', 'F6 CC', 'F7 CD', 'F8 DT', 'F9 EX', 'F10 FW', 'F11 IN', 'F12 JJ',\n",
    "       'F13 JJR', 'F14 JJS', 'F15 LS', 'F16 MD', 'F17 NN', 'F18 NNP',\n",
    "       'F19 NNPS', 'F20 NNS', 'F21 PDT', 'F22 POS', 'F23 PRP', 'F24 PRP$',\n",
    "       'F25 RB', 'F26 RBR', 'F27 RBS', 'F28 RP', 'F29 SYM', 'F30 TO', 'F31 UH',\n",
    "       'F32 VB', 'F33 VBD', 'F34 VBG', 'F35 VBN', 'F36 VBP', 'F37 VBZ',\n",
    "       'F38 WDT', 'F39 WP', 'F40 WP$', 'F41 WRB',\n",
    "       'F42 Sentence Complexity', \n",
    "       'F43 !', 'F44 \\'', 'F45 ,', 'F46 .', 'F47 :', 'F48 ;', 'F49 ?',\n",
    "       'F50 Readability Score', 'F51 Formality Score', 'F52 Politeness Degree',\n",
    "       'F53 Sentiment Polarity', 'F54 Subjectivity',\n",
    "       'F55 Topic 1', 'F56 Topic 2', 'F57 Topic 3', 'F58 Topic 4']\n",
    "\n",
    "df_features = df_samples[features]\n",
    "df_validation_features = df_validation[features]\n",
    "\n",
    "# Fill all NaN values with 0\n",
    "df_features = df_features.fillna(0)\n",
    "df_features.columns = df_features.columns.astype(str)\n",
    "\n",
    "df_validation_features = df_validation_features.fillna(0)\n",
    "df_validation_features.columns = df_validation_features.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.to_csv('features.csv')\n",
    "df_validation_features.to_csv('validation_features.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
